{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ESU9o32dkue"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import torch  # Core library for PyTorch\n",
        "import torch.nn as nn  # For building neural networks\n",
        "import torch.optim as optim  # For optimization algorithms\n",
        "import torchvision.transforms as transforms  # For image transformations\n",
        "import torchvision.datasets as datasets  # For standard datasets\n",
        "from torchvision.utils import save_image  # For saving images\n",
        "import numpy as np  # For numerical operations\n",
        "import os  # For interacting with the operating system\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Set the device to GPU if available, else CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define the U-Net model\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(UNet, self).__init__()\n",
        "        # Encoder part of U-Net: Downsampling layers\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, kernel_size=4, stride=2, padding=1),  # Convolution layer\n",
        "            nn.ReLU(),  # Activation function\n",
        "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),  # Convolution layer\n",
        "            nn.ReLU()  # Activation function\n",
        "        )\n",
        "        # Middle part of U-Net: Bottleneck layers\n",
        "        self.middle = nn.Sequential(\n",
        "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),  # Convolution layer\n",
        "            nn.ReLU(),  # Activation function\n",
        "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),  # Convolution layer\n",
        "            nn.ReLU()  # Activation function\n",
        "        )\n",
        "        # Decoder part of U-Net: Upsampling layers\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),  # Transpose convolution layer\n",
        "            nn.ReLU(),  # Activation function\n",
        "            nn.ConvTranspose2d(64, 1, kernel_size=4, stride=2, padding=1),  # Transpose convolution layer\n",
        "            nn.Tanh()  # Activation function, scales output between -1 and 1\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)  # Apply encoder\n",
        "        x = self.middle(x)  # Apply middle part\n",
        "        x = self.decoder(x)  # Apply decoder\n",
        "        return x\n",
        "\n",
        "class Diffusion:\n",
        "    def __init__(self, num_steps=1000):\n",
        "        super(Diffusion, self).__init__()\n",
        "        self.num_steps = num_steps\n",
        "        self.beta = np.linspace(0.0001, 0.02, num_steps)\n",
        "        self.alpha = 1.0 - self.beta\n",
        "        self.alpha_bar = torch.tensor(np.cumprod(self.alpha), dtype=torch.float32)  # Convert to PyTorch tensor\n",
        "\n",
        "    def q_sample(self, x_start, t, noise=None):\n",
        "        if noise is None:\n",
        "            noise = torch.randn_like(x_start)\n",
        "\n",
        "        sqrt_alpha_bar_t = torch.sqrt(self.alpha_bar[t])  # Use PyTorch sqrt function\n",
        "        sqrt_one_minus_alpha_bar_t = torch.sqrt(1 - self.alpha_bar[t])\n",
        "\n",
        "        return sqrt_alpha_bar_t * x_start + sqrt_one_minus_alpha_bar_t * noise\n",
        "\n",
        "    def p_sample(self, x_t, t, model):\n",
        "        x_t = x_t.to(device)\n",
        "        t = t.to(device)\n",
        "        noise = torch.randn_like(x_t)\n",
        "        predicted_noise = model(x_t, t)\n",
        "\n",
        "        sqrt_alpha_t = torch.sqrt(1 / self.alpha[t])\n",
        "        sqrt_one_minus_alpha_bar_t = torch.sqrt(1 - self.alpha_bar[t])\n",
        "\n",
        "        return sqrt_alpha_t * (\n",
        "            x_t - ((1 - self.alpha[t]) / sqrt_one_minus_alpha_bar_t) * predicted_noise\n",
        "        ) + noise\n",
        "\n"
      ],
      "metadata": {
        "id": "zCxG3OXxhLe7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "cc4180af-d96e-4cb2-f8f5-918c5a68a6f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'torch' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-57aa85815512>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Set the device to GPU if available, else CPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Define the U-Net model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mUNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Instantiate the U-Net model and move it to the appropriate device\n",
        "model = UNet().to(device)\n",
        "# Instantiate the diffusion process\n",
        "diffusion = Diffusion()\n",
        "\n",
        "# Set hyperparameters\n",
        "batch_size = 64  # Batch size for training\n",
        "learning_rate = 1e-4  # Learning rate for optimizer\n",
        "num_epochs = 10  # Number of training epochs\n",
        "\n",
        "# Load and transform the dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((28, 28)),  # Resize images to 28x28\n",
        "    transforms.ToTensor(),  # Convert images to tensor\n",
        "    transforms.Normalize((0.5,), (0.5,))  # Normalize images\n",
        "])\n",
        "\n",
        "# Download and load the MNIST dataset\n",
        "dataset = datasets.MNIST(root='dataset/', train=True, transform=transform, download=True)\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Define optimizer and loss function\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)  # Adam optimizer\n",
        "criterion = nn.MSELoss()  # Mean Squared Error loss\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "78Q6InwehRl7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    for idx, (x, _) in enumerate(dataloader):\n",
        "        x = x.to(device)  # Move input to the correct device\n",
        "        print(x.shape)\n",
        "        t = torch.randint(0, diffusion.num_steps, (batch_size,), device=device).long()  # Random time steps\n",
        "\n",
        "        noise = torch.randn_like(x)  # Generate noise\n",
        "        x_t = diffusion.q_sample(x, t, noise)  # Apply forward diffusion\n",
        "        predicted_noise = model(x_t, t)  # Predict noise with the model\n",
        "\n",
        "        loss = criterion(predicted_noise, noise)  # Calculate loss\n",
        "        optimizer.zero_grad()  # Zero the gradients\n",
        "        loss.backward()  # Backpropagation\n",
        "        optimizer.step()  # Update model parameters\n",
        "\n",
        "        # Print loss every 100 batches\n",
        "        if idx % 100 == 0:\n",
        "            print(f\"Epoch [{epoch}/{num_epochs}] Batch [{idx}/{len(dataloader)}] Loss: {loss.item():.4f}\")\n",
        "\n",
        "# Function to generate and save images\n",
        "def sample_images(model, diffusion, num_samples=64):\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    with torch.no_grad():  # Disable gradient calculation\n",
        "        x = torch.randn(num_samples, 1, 28, 28).to(device)  # Generate random noise\n",
        "        for t in reversed(range(diffusion.num_steps)):  # Reverse diffusion process\n",
        "            t_batch = torch.tensor([t] * num_samples, device=device).long()  # Time steps batch\n",
        "            x = diffusion.p_sample(x, t_batch, model)  # Denoise\n",
        "        save_image(x, os.path.join('samples', f'sample.png'), normalize=True)  # Save generated images\n",
        "\n",
        "# Create samples directory if it does not exist\n",
        "if not os.path.exists('samples'):\n",
        "    os.makedirs('samples')\n",
        "\n",
        "# Generate and save images from the trained model\n",
        "sample_images(model, diffusion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "id": "LUL8RYLxhW8L",
        "outputId": "857e1ebf-d130-4eef-f837-812cbd975db3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 1, 28, 28])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "The size of tensor a (64) must match the size of tensor b (28) at non-singleton dimension 3",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-834169697402>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Generate noise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mx_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiffusion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Apply forward diffusion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mpredicted_noise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Predict noise with the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-cb9e78adb7a4>\u001b[0m in \u001b[0;36mq_sample\u001b[0;34m(self, x_start, t, noise)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0msqrt_one_minus_alpha_bar_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha_bar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msqrt_alpha_bar_t\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx_start\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msqrt_one_minus_alpha_bar_t\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mp_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (64) must match the size of tensor b (28) at non-singleton dimension 3"
          ]
        }
      ]
    }
  ]
}